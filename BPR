import numpy as np
import json
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import os
import time
import copy
from datetime import datetime
import matplotlib.pyplot as plt
import sys

# GPU ë””ë²„ê¹… í•¨ìˆ˜ ì¶”ê°€
def check_gpu_status():
    """GPU ìƒíƒœ í™•ì¸ ë° ë””ë²„ê¹… ì •ë³´ ì¶œë ¥"""
    print("\n" + "="*50)
    print("GPU ë° ì‹œìŠ¤í…œ ì •ë³´")
    print("="*50)
    
    print(f"Python ë²„ì „: {sys.version}")
    print(f"PyTorch ë²„ì „: {torch.__version__}")
    print(f"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"CUDA ë²„ì „: {torch.version.cuda}")
        print(f"CUDA ê¸°ê¸° ìˆ˜: {torch.cuda.device_count()}")
        print(f"í˜„ì¬ CUDA ê¸°ê¸°: {torch.cuda.current_device()}")
        print(f"CUDA ê¸°ê¸° ì´ë¦„: {torch.cuda.get_device_name(0)}")
        
        # ê°„ë‹¨í•œ GPU ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸
        try:
            # í…ì„œ ìƒì„±
            print("\nGPU ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸ ì¤‘...")
            x = torch.rand(1000, 1000).cuda()
            y = torch.matmul(x, x.t())
            
            # ë©”ëª¨ë¦¬ ì •ë³´
            allocated = torch.cuda.memory_allocated() / 1024**2
            reserved = torch.cuda.memory_reserved() / 1024**2
            print(f"GPU í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
            print(f"  í• ë‹¹ëœ ë©”ëª¨ë¦¬: {allocated:.2f} MB")
            print(f"  ì˜ˆì•½ëœ ë©”ëª¨ë¦¬: {reserved:.2f} MB")
            del x, y
            torch.cuda.empty_cache()
        except Exception as e:
            print(f"GPU í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
    else:
        print("GPU ì‚¬ìš© ë¶ˆê°€ - CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
    
    print("\nCUDA í™˜ê²½ ë³€ìˆ˜:")
    for env_var in ["CUDA_VISIBLE_DEVICES", "CUDA_HOME", "LD_LIBRARY_PATH"]:
        print(f"  {env_var}: {os.environ.get(env_var, 'ì„¤ì •ë˜ì§€ ì•ŠìŒ')}")
    
    print("="*50 + "\n")
    
    return torch.cuda.is_available()

# 1. ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜
class BPRDataset(Dataset):
    def __init__(self, triplet_file):
        """
        íŠ¸ë¦¬í”Œë › íŒŒì¼ë¡œë¶€í„° BPR ë°ì´í„°ì…‹ ìƒì„±
        
        Args:
            triplet_file: íŠ¸ë¦¬í”Œë › JSON íŒŒì¼ ê²½ë¡œ
        """
        start_time = time.time()
        
        # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•œ JSON ë¡œë”© ì„¤ì •
        print(f"ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘: {triplet_file}")
        with open(triplet_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
        self.triplets = data['triplets']
        self.metadata = data['metadata']
        self.user_id_map = data.get('user_id_map', {})
        self.business_id_map = data.get('business_id_map', {})
        
        # ë°ì´í„°ì…‹ ì •ë³´ ì¶œë ¥
        print(f"ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ:")
        print(f"- ì´ íŠ¸ë¦¬í”Œë › ìˆ˜: {len(self.triplets)}")
        print(f"- ì‚¬ìš©ì ìˆ˜: {self.metadata.get('num_users', 0)}")
        print(f"- ë¹„ì¦ˆë‹ˆìŠ¤ ìˆ˜: {self.metadata.get('num_businesses', 0)}")
        
        # NumPy ë°°ì—´ë¡œ ë³€í™˜ (ë” ë¹ ë¥¸ ì²˜ë¦¬ë¥¼ ìœ„í•´)
        if isinstance(self.triplets[0], list):
            self.data = np.array(self.triplets, dtype=np.int64)
        else:
            # tripletsê°€ ë”•ì…”ë„ˆë¦¬ í˜•íƒœì¸ ê²½ìš°
            self.data = np.array([[t.get('user', 0), t.get('item', 0), t.get('rating', 0)] 
                               for t in self.triplets], dtype=np.int64)
        
        # Positiveì™€ Negative ìƒ˜í”Œ ë¶„ë¦¬
        self.pos_samples = self.data[self.data[:, 2] == 1]
        self.neg_samples = self.data[self.data[:, 2] == 0]
        
        # ë” íš¨ìœ¨ì ì¸ ê²€ìƒ‰ì„ ìœ„í•´ ì‚¬ìš©ìë³„ negative ì•„ì´í…œ ì¸ë±ìŠ¤ ë¯¸ë¦¬ ê³„ì‚°
        self.user_neg_items = {}
        for user_id in np.unique(self.pos_samples[:, 0]):
            neg_indices = np.where((self.neg_samples[:, 0] == user_id))[0]
            if len(neg_indices) > 0:
                self.user_neg_items[int(user_id)] = neg_indices
        
        # ëª¨ë“  ì‚¬ìš©ìì˜ ëª¨ë“  positive ì•„ì´í…œ ì €ì¥ (ì¶”ì²œì—ì„œ ì œì™¸í•˜ê¸° ìœ„í•´)
        self.user_pos_items = {}
        for user_id in np.unique(self.pos_samples[:, 0]):
            pos_items = self.pos_samples[self.pos_samples[:, 0] == user_id][:, 1]
            self.user_pos_items[int(user_id)] = pos_items
        
        # ì•„ì´í…œ ì¸ê¸°ë„ ê³„ì‚° (ê°œì„ ëœ ë„¤ê±°í‹°ë¸Œ ìƒ˜í”Œë§ì— ì‚¬ìš©)
        item_counts = np.bincount(self.pos_samples[:, 1])
        self.item_popularity = item_counts / np.sum(item_counts)
        
        print(f"- Positive ìƒ˜í”Œ: {len(self.pos_samples)}")
        print(f"- Negative ìƒ˜í”Œ: {len(self.neg_samples)}")
        print(f"- ë°ì´í„° ë¡œë”© ì‹œê°„: {time.time() - start_time:.2f}ì´ˆ")
    
    def __len__(self):
        return len(self.pos_samples)
    
    def __getitem__(self, idx):
        """
        BPR í•™ìŠµì„ ìœ„í•œ (user, pos_item, neg_item) ìƒ˜í”Œ ë°˜í™˜
        
        ëª¨ë“  Positive ìƒ˜í”Œì— ëŒ€í•´ ë¬´ì‘ìœ„ Negative ìƒ˜í”Œ ì„ íƒ
        """
        # Positive ìƒ˜í”Œ ê°€ì ¸ì˜¤ê¸°
        user_id, pos_item, _ = self.pos_samples[idx]
        user_id = int(user_id)  # numpy int64ë¥¼ python intë¡œ ë³€í™˜
        
        # ì´ ì‚¬ìš©ìë¥¼ ìœ„í•œ Negative ìƒ˜í”Œ ì„ íƒ
        if user_id in self.user_neg_items and len(self.user_neg_items[user_id]) > 0:
            # ì €ì¥ëœ negative ìƒ˜í”Œì—ì„œ ì„ íƒ
            neg_idx = np.random.choice(self.user_neg_items[user_id])
            _, neg_item, _ = self.neg_samples[neg_idx]
        else:
            # ê°œì„ ëœ ë„¤ê±°í‹°ë¸Œ ìƒ˜í”Œë§ - ì¸ê¸°ë„ ê¸°ë°˜ & í•˜ë“œ ë„¤ê±°í‹°ë¸Œ
            num_items = self.metadata.get('num_businesses', 10000)
            
            if user_id in self.user_pos_items and len(self.user_pos_items[user_id]) > 0:
                # ëª¨ë“  ì•„ì´í…œ ì¤‘ì—ì„œ í˜„ì¬ ì‚¬ìš©ìì˜ positive ì•„ì´í…œ ì œì™¸
                pos_items = self.user_pos_items[user_id]
                candidate_items = np.setdiff1d(np.arange(num_items), pos_items)
                
                if len(candidate_items) > 0:
                    # ì¸ê¸°ë„ ê¸°ë°˜ ìƒ˜í”Œë§ (ì¸ê¸° ìˆëŠ” ì•„ì´í…œì„ ë” ìì£¼ ì„ íƒ)
                    # 80%ëŠ” ì¸ê¸°ë„ ê¸°ë°˜ ìƒ˜í”Œë§, 20%ëŠ” ì™„ì „ ë¬´ì‘ìœ„ ìƒ˜í”Œë§
                    if np.random.random() < 0.8 and hasattr(self, 'item_popularity'):
                        # ì¸ê¸°ë„ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•œ ìƒ˜í”Œë§
                        probs = self.item_popularity[candidate_items]
                        probs = probs / np.sum(probs)  # ì •ê·œí™”
                        neg_item = np.random.choice(candidate_items, p=probs)
                    else:
                        neg_item = np.random.choice(candidate_items)
                else:
                    # ê·¹ë‹¨ì ì¸ ê²½ìš°: ëª¨ë“  ì•„ì´í…œì´ positiveì¸ ê²½ìš°
                    neg_item = np.random.randint(0, num_items)
            else:
                # ì‚¬ìš©ìì— ëŒ€í•œ positive ì •ë³´ê°€ ì—†ìœ¼ë©´ ëœë¤ ì„ íƒ
                neg_item = np.random.randint(0, num_items)
        
        return {
            'user': torch.tensor([user_id], dtype=torch.long),
            'pos_item': torch.tensor([pos_item], dtype=torch.long),
            'neg_item': torch.tensor([neg_item], dtype=torch.long)
        }


# 2. BPR ëª¨ë¸ ì •ì˜
class BPRModel(nn.Module):
    def __init__(self, num_users, num_items, embedding_dim=128):
        """
        Bayesian Personalized Ranking ëª¨ë¸
        
        Args:
            num_users: ì‚¬ìš©ì ìˆ˜
            num_items: ì•„ì´í…œ(ë¹„ì¦ˆë‹ˆìŠ¤) ìˆ˜
            embedding_dim: ì„ë² ë”© ì°¨ì›
        """
        super(BPRModel, self).__init__()
        
        # ì„ë² ë”© ì°¨ì› ì €ì¥ (ì¶œë ¥ìš©)
        self.embedding_dim = embedding_dim
        print(f"BPRModel ì´ˆê¸°í™”: ì„ë² ë”© ì°¨ì› = {embedding_dim}")
        
        # ì‚¬ìš©ì ì„ë² ë”©
        self.user_embeddings = nn.Embedding(num_users, embedding_dim)
        # ì•„ì´í…œ ì„ë² ë”©
        self.item_embeddings = nn.Embedding(num_items, embedding_dim)
        
        # ì„ë² ë”© ì´ˆê¸°í™” (í‘œì¤€í¸ì°¨ ê°ì†Œ)
        nn.init.normal_(self.user_embeddings.weight, std=0.01)
        nn.init.normal_(self.item_embeddings.weight, std=0.01)
        
        # ì°¨ì› ì €ì¥ (ëª¨ë¸ ì§ë ¬í™”ë¥¼ ìœ„í•´)
        self.num_users = num_users
        self.num_items = num_items
    
    def forward(self, user, pos_item, neg_item):
        """
        BPR ëª¨ë¸ í¬ì›Œë“œ íŒ¨ìŠ¤
        
        Args:
            user: ì‚¬ìš©ì ì¸ë±ìŠ¤
            pos_item: ê¸ì •ì  ì•„ì´í…œ ì¸ë±ìŠ¤
            neg_item: ë¶€ì •ì  ì•„ì´í…œ ì¸ë±ìŠ¤
            
        Returns:
            pos_scores: ì‚¬ìš©ì-ê¸ì •ì  ì•„ì´í…œ ì ìˆ˜
            neg_scores: ì‚¬ìš©ì-ë¶€ì •ì  ì•„ì´í…œ ì ìˆ˜
        """
        # ì„ë² ë”© ê²€ìƒ‰
        user_embedding = self.user_embeddings(user)
        pos_item_embedding = self.item_embeddings(pos_item)
        neg_item_embedding = self.item_embeddings(neg_item)
        
        # ì ìˆ˜ ê³„ì‚° (ë‚´ì )
        pos_scores = torch.sum(user_embedding * pos_item_embedding, dim=-1)
        neg_scores = torch.sum(user_embedding * neg_item_embedding, dim=-1)
        
        return pos_scores, neg_scores
    
    def predict(self, user_indices, item_indices=None):
        """
        ì‚¬ìš©ì-ì•„ì´í…œ ì ìˆ˜ ì˜ˆì¸¡
        
        Args:
            user_indices: ì‚¬ìš©ì ì¸ë±ìŠ¤ ë°°ì—´ ë˜ëŠ” ë‹¨ì¼ ì¸ë±ìŠ¤
            item_indices: ì•„ì´í…œ ì¸ë±ìŠ¤ ë°°ì—´ ë˜ëŠ” ë‹¨ì¼ ì¸ë±ìŠ¤ (Noneì´ë©´ ëª¨ë“  ì•„ì´í…œ)
            
        Returns:
            ì˜ˆì¸¡ ì ìˆ˜
        """
        device = self.user_embeddings.weight.device
        
        # ë‹¨ì¼ ì‚¬ìš©ì, ëª¨ë“  ì•„ì´í…œ ì ìˆ˜ ê³„ì‚°
        if item_indices is None:
            users = torch.tensor([user_indices], dtype=torch.long, device=device)
            user_embedding = self.user_embeddings(users)
            all_item_embeddings = self.item_embeddings.weight
            
            # í–‰ë ¬ ê³±ìœ¼ë¡œ ëª¨ë“  ì•„ì´í…œ ì ìˆ˜ ê³„ì‚°
            scores = torch.matmul(user_embedding, all_item_embeddings.t())
            return scores.squeeze()
        
        # ì§€ì •ëœ ì‚¬ìš©ì-ì•„ì´í…œ í˜ì–´ ì ìˆ˜ ê³„ì‚°
        users = torch.tensor(user_indices, dtype=torch.long, device=device)
        items = torch.tensor(item_indices, dtype=torch.long, device=device)
        
        user_embedding = self.user_embeddings(users)
        item_embedding = self.item_embeddings(items)
        
        # ìš”ì†Œë³„ ê³± ë° í•©ì‚°
        return torch.sum(user_embedding * item_embedding, dim=-1)


# 3. BPR ì†ì‹¤ í•¨ìˆ˜
class BPRLoss(nn.Module):
    def __init__(self):
        super(BPRLoss, self).__init__()
    
    def forward(self, pos_scores, neg_scores):
        """
        BPR ì†ì‹¤ ê³„ì‚°: -log(sigmoid(pos_scores - neg_scores))
        
        Args:
            pos_scores: ì‚¬ìš©ì-ê¸ì •ì  ì•„ì´í…œ ì ìˆ˜
            neg_scores: ì‚¬ìš©ì-ë¶€ì •ì  ì•„ì´í…œ ì ìˆ˜
            
        Returns:
            ì†ì‹¤ê°’
        """
        # ìˆ«ì ì•ˆì •ì„±ì„ ìœ„í•œ epsilon ìµœì í™”
        epsilon = 1e-8  # ë„ˆë¬´ ì‘ì€ ê°’ì€ ìˆ«ì ë¶ˆì•ˆì •ì„±, ë„ˆë¬´ í° ê°’ì€ ì •í™•ë„ ì†ì‹¤
        loss = -torch.log(torch.sigmoid(pos_scores - neg_scores) + epsilon)
        return loss.mean()


# ëª¨ë¸ ë²„ì „ ê´€ë¦¬ ìœ„í•œ í•¨ìˆ˜ ì¶”ê°€
def get_next_model_version(output_dir):
    """
    ë‹¤ìŒ ëª¨ë¸ ë²„ì „ ë²ˆí˜¸ë¥¼ ê²°ì •
    
    Args:
        output_dir: ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬
        
    Returns:
        ë‹¤ìŒ ëª¨ë¸ ë²„ì „ ë²ˆí˜¸
    """
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        return 1
    
    # ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  ëª¨ë¸ íŒŒì¼ ê²€ìƒ‰
    model_files = [f for f in os.listdir(output_dir) if f.startswith('bpr_model_') and f.endswith('.pt')]
    
    if not model_files:
        return 1
    
    # ë²„ì „ ë²ˆí˜¸ ì¶”ì¶œ ë° ìµœëŒ€ê°’ ì°¾ê¸°
    versions = []
    for file in model_files:
        try:
            # bpr_model_X.pt í˜•ì‹ì—ì„œ X ì¶”ì¶œ
            version_str = file.replace('bpr_model_', '').replace('.pt', '')
            version = int(version_str)
            versions.append(version)
        except ValueError:
            continue
    
    if versions:
        return max(versions) + 1
    else:
        return 1


# ë°ì´í„°ì…‹ ë¶„í•  í•¨ìˆ˜ ì¶”ê°€
def split_dataset(dataset, train_ratio=0.6, val_ratio=0.2, test_ratio=0.2, min_interactions=3):
    """
    ë°ì´í„°ì…‹ì„ í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë¶„í• 
    
    Args:
        dataset: BPR ë°ì´í„°ì…‹
        train_ratio: í•™ìŠµ ë°ì´í„° ë¹„ìœ¨
        val_ratio: ê²€ì¦ ë°ì´í„° ë¹„ìœ¨
        test_ratio: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨
        min_interactions: ì‚¬ìš©ìë³„ ìµœì†Œ ìƒí˜¸ì‘ìš© ìˆ˜
    
    Returns:
        ë¶„í• ëœ ë°ì´í„°ì…‹ (í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸)
    """
    assert train_ratio + val_ratio + test_ratio == 1.0, "ë¹„ìœ¨ì˜ í•©ì€ 1.0ì´ì–´ì•¼ í•©ë‹ˆë‹¤."
    
    # ì‚¬ìš©ìë³„ ìƒí˜¸ì‘ìš© ë°ì´í„° ìˆ˜ì§‘
    user_interactions = {}
    
    # ì „ì²´ ìƒí˜¸ì‘ìš© ë°ì´í„°ì—ì„œ ì‚¬ìš©ìë³„ë¡œ ê·¸ë£¹í™”
    for user_id in np.unique(dataset.pos_samples[:, 0]):
        user_id = int(user_id)
        # í˜„ì¬ ì‚¬ìš©ìì˜ ëª¨ë“  positive ìƒí˜¸ì‘ìš©
        user_items = dataset.pos_samples[dataset.pos_samples[:, 0] == user_id][:, 1]
        
        # ìµœì†Œ ìƒí˜¸ì‘ìš© ìˆ˜ í•„í„°ë§
        if len(user_items) >= min_interactions:
            # ì…”í”Œ
            np.random.shuffle(user_items)
            
            # í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë¶„í•  ê²½ê³„ ê³„ì‚°
            train_idx = int(len(user_items) * train_ratio)
            val_idx = train_idx + int(len(user_items) * val_ratio)
            
            train_items = user_items[:train_idx]
            val_items = user_items[train_idx:val_idx]
            test_items = user_items[val_idx:]
            
            user_interactions[user_id] = {
                'train': train_items,
                'val': val_items,
                'test': test_items
            }
    
    print(f"Dataset split completed:")
    print(f"- Users processed: {len(user_interactions)}")
    print(f"- Split ratio: Train {train_ratio:.1f}, Validation {val_ratio:.1f}, Test {test_ratio:.1f}")
    
    return user_interactions


# ë©”íŠ¸ë¦­ ê³„ì‚° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì¶”ê°€ (ì¤‘ë³µ ì½”ë“œ ì œê±°)
def calculate_recommendation_metrics(recommended_items, test_items, k):
    """
    ì¶”ì²œ ì‹œìŠ¤í…œ í‰ê°€ ë©”íŠ¸ë¦­ ê³„ì‚°ì„ ìœ„í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
    
    Args:
        recommended_items: ì¶”ì²œëœ ì•„ì´í…œ ì¸ë±ìŠ¤ ë°°ì—´
        test_items: í…ŒìŠ¤íŠ¸(ë˜ëŠ” ê²€ì¦) ì•„ì´í…œ ì¸ë±ìŠ¤ ë°°ì—´
        k: ì¶”ì²œ ì•„ì´í…œ ìˆ˜
        
    Returns:
        precision_at_k, recall_at_k, ndcg_score íŠœí”Œ
    """
    # MAP@K (Mean Average Precision at K)
    precision_at_k = len(set(recommended_items) & set(test_items)) / k
    
    # Recall@K
    recall_at_k = 0
    if len(test_items) > 0:
        recall_at_k = len(set(recommended_items) & set(test_items)) / len(test_items)
    
    # NDCG@K
    dcg = 0
    for i, item in enumerate(recommended_items[:k]):
        if item in test_items:
            # ìˆœìœ„ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ ì ìš©
            dcg += 1 / np.log2(i + 2)  # log2(1+1) = 1ì´ë¯€ë¡œ (i+2)ë¡œ ê³„ì‚°
    
    # IDCG@K ê³„ì‚° (ì´ìƒì ì¸ ê²½ìš°)
    idcg = 0
    for i in range(min(len(test_items), k)):
        idcg += 1 / np.log2(i + 2)
    
    # NDCG@K = DCG@K / IDCG@K
    ndcg_score = dcg / idcg if idcg > 0 else 0.0
    
    return precision_at_k, recall_at_k, ndcg_score


# ê³µí†µ í‰ê°€ ë¡œì§ì„ ìœ„í•œ í•¨ìˆ˜ ì¶”ê°€
def evaluate_recommendations(
    model, 
    users,
    interactions_dict,
    top_k=10, 
    interaction_type='test',  # 'test' ë˜ëŠ” 'val'
    mask_items_key='train',   # ë§ˆìŠ¤í‚¹í•  ì•„ì´í…œ ('train' ë˜ëŠ” ['train', 'val'])
    device="cuda" if torch.cuda.is_available() else "cpu"
):
    """
    ëª¨ë¸ ì¶”ì²œ ì„±ëŠ¥ í‰ê°€ë¥¼ ìœ„í•œ í†µí•© í•¨ìˆ˜
    
    Args:
        model: í‰ê°€í•  BPR ëª¨ë¸
        users: í‰ê°€í•  ì‚¬ìš©ì ID ë¦¬ìŠ¤íŠ¸
        interactions_dict: ì‚¬ìš©ìë³„ ìƒí˜¸ì‘ìš© ë”•ì…”ë„ˆë¦¬ (user_id -> {'train': [...], 'val': [...], 'test': [...]})
        top_k: ì¶”ì²œ ì•„ì´í…œ ìˆ˜
        interaction_type: í‰ê°€í•  ìƒí˜¸ì‘ìš© ìœ í˜• ('test' ë˜ëŠ” 'val')
        mask_items_key: ë§ˆìŠ¤í‚¹í•  ì•„ì´í…œ í‚¤ ('train' ë˜ëŠ” ['train', 'val'])
        device: ê³„ì‚° ì¥ì¹˜
    
    Returns:
        í‰ê°€ ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
    """
    model.eval()
    
    # ë©”íŠ¸ë¦­ ì´ˆê¸°í™”
    metrics = {
        f'MAP@{top_k}': [],
        f'Recall@{top_k}': [],
        f'NDCG@{top_k}': []
    }
    
    with torch.no_grad():
        for i, user_id in enumerate(users):
            if i % 100 == 0 and i > 0:
                print(f"  {i}/{len(users)} users evaluated")
            
            # í•™ìŠµ ë° í…ŒìŠ¤íŠ¸/ê²€ì¦ ì•„ì´í…œ ê°€ì ¸ì˜¤ê¸°
            if isinstance(mask_items_key, list):
                # ì—¬ëŸ¬ ì•„ì´í…œ ì„¸íŠ¸ ë§ˆìŠ¤í‚¹ (ì˜ˆ: train + val)
                mask_items = np.concatenate([interactions_dict[user_id][key] for key in mask_items_key])
            else:
                # ë‹¨ì¼ ì•„ì´í…œ ì„¸íŠ¸ ë§ˆìŠ¤í‚¹ (ì˜ˆ: train)
                mask_items = interactions_dict[user_id][mask_items_key]
            
            # í…ŒìŠ¤íŠ¸/ê²€ì¦ ì•„ì´í…œ
            eval_items = interactions_dict[user_id][interaction_type]
            
            if len(eval_items) == 0:
                continue
            
            # ì‚¬ìš©ì ì•„ì´í…œ ì ìˆ˜ ì˜ˆì¸¡
            scores = model.predict(user_id)
            scores = scores.cpu().numpy()
            
            # í•™ìŠµ ì•„ì´í…œ ë§ˆìŠ¤í‚¹
            scores[mask_items] = -np.inf
            
            # Top-K ì•„ì´í…œ ì¶”ì¶œ
            recommended_items = np.argsort(-scores)[:top_k]
            
            # ë©”íŠ¸ë¦­ ê³„ì‚°
            precision, recall, ndcg = calculate_recommendation_metrics(
                recommended_items, eval_items, top_k
            )
            
            metrics[f'MAP@{top_k}'].append(precision)
            metrics[f'Recall@{top_k}'].append(recall)
            metrics[f'NDCG@{top_k}'].append(ndcg)
    
    # í‰ê·  ë©”íŠ¸ë¦­ ê³„ì‚°
    avg_metrics = {}
    for metric, values in metrics.items():
        if values:
            avg_metrics[metric] = np.mean(values)
        else:
            avg_metrics[metric] = 0.0
    
    return avg_metrics


# validate_epoch í•¨ìˆ˜ ìˆ˜ì •
def validate_epoch(model, user_interactions, top_k=10, max_users=1000, device="cuda" if torch.cuda.is_available() else "cpu"):
    """
    ê²€ì¦ ì„¸íŠ¸ì—ì„œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
    
    Args:
        model: BPR ëª¨ë¸
        user_interactions: ë¶„í• ëœ ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ë°ì´í„°
        top_k: ì¶”ì²œ ì•„ì´í…œ ìˆ˜
        max_users: í‰ê°€í•  ìµœëŒ€ ì‚¬ìš©ì ìˆ˜
        device: ê³„ì‚° ì¥ì¹˜
    
    Returns:
        ê²€ì¦ ì„±ëŠ¥ ì§€í‘œ (MAP, Recall, NDCG)
    """
    # í‰ê°€í•  ì‚¬ìš©ì ì„ íƒ (ìµœëŒ€ max_usersëª…)
    eval_users = list(user_interactions.keys())
    if len(eval_users) > max_users:
        eval_users = np.random.choice(eval_users, max_users, replace=False)
    
    # ê³µí†µ í‰ê°€ í•¨ìˆ˜ ì‚¬ìš©
    metrics = evaluate_recommendations(
        model, 
        eval_users, 
        user_interactions, 
        top_k=top_k, 
        interaction_type='val',  # ê²€ì¦ ì„¸íŠ¸ ì‚¬ìš©
        mask_items_key='train',  # í•™ìŠµ ì•„ì´í…œë§Œ ë§ˆìŠ¤í‚¹
        device=device
    )
    
    # í‚¤ ì´ë¦„ ë³€í™˜ (MAP@10 -> MAP ë“±)ìœ¼ë¡œ train_bpr_modelê³¼ í˜¸í™˜ë˜ë„ë¡ í•¨
    return {
        'MAP': metrics[f'MAP@{top_k}'],
        'Recall': metrics[f'Recall@{top_k}'],
        'NDCG': metrics[f'NDCG@{top_k}']
    }


# evaluate_test_set í•¨ìˆ˜ ìˆ˜ì • (ê³µí†µ í•¨ìˆ˜ ì‚¬ìš©)
def evaluate_test_set(model, user_interactions, top_k=10, device="cuda" if torch.cuda.is_available() else "cpu"):
    """
    í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
    
    Args:
        model: BPR ëª¨ë¸
        user_interactions: ë¶„í• ëœ ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ë°ì´í„°
        top_k: ì¶”ì²œ ì•„ì´í…œ ìˆ˜
        device: ê³„ì‚° ì¥ì¹˜
    
    Returns:
        í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ ì§€í‘œ (MAP, Recall, NDCG)
    """
    # í…ŒìŠ¤íŠ¸ ì‚¬ìš©ì ê°€ì ¸ì˜¤ê¸°
    test_users = list(user_interactions.keys())
    
    print(f"Test users: {len(test_users)}")
    
    # ê³µí†µ í‰ê°€ í•¨ìˆ˜ ì‚¬ìš©
    return evaluate_recommendations(
        model, 
        test_users, 
        user_interactions, 
        top_k=top_k, 
        interaction_type='test',          # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì‚¬ìš©
        mask_items_key=['train', 'val'],  # í•™ìŠµ ë° ê²€ì¦ ì•„ì´í…œ ë§ˆìŠ¤í‚¹
        device=device
    )


# ëª¨ë¸ í‰ê°€ í•¨ìˆ˜ë„ í†µí•© í•¨ìˆ˜ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •
def evaluate_model(
    model,
    dataset,
    top_k=10,
    num_users=None,
    test_ratio=0.2,
    min_interactions=3,
    device="cuda" if torch.cuda.is_available() else "cpu"
):
    """
    ëª¨ë¸ ì„±ëŠ¥ í‰ê°€: MAP@K, Recall@K, NDCG@K
    
    Args:
        model: í•™ìŠµëœ BPR ëª¨ë¸
        dataset: BPR ë°ì´í„°ì…‹
        top_k: ì¶”ì²œ ì•„ì´í…œ ìˆ˜ (Default: 10)
        num_users: í‰ê°€í•  ì‚¬ìš©ì ìˆ˜ (Noneì´ë©´ ëª¨ë“  ì‚¬ìš©ì)
        test_ratio: í…ŒìŠ¤íŠ¸ ë¹„ìœ¨ (Default: 0.2)
        min_interactions: í‰ê°€ì— í¬í•¨í•  ì‚¬ìš©ìì˜ ìµœì†Œ ìƒí˜¸ì‘ìš© ìˆ˜ (Default: 3)
        device: ê³„ì‚° ì¥ì¹˜
        
    Returns:
        í‰ê°€ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ (MAP@K, Recall@K, NDCG@K)
    """
    print(f"\n{'='*50}")
    print(f"ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ (K={top_k})")
    print(f"{'='*50}")
    
    model.eval()
    model = model.to(device)
    
    # ì‚¬ìš©ìë³„ ìƒí˜¸ì‘ìš© ë¶„ë¦¬ (í•™ìŠµ/í…ŒìŠ¤íŠ¸) - ë°ì´í„°ì…‹ ë¶„í•  í•¨ìˆ˜ì™€ ë¡œì§ì´ ì¤‘ë³µë¨
    # ì´ í•¨ìˆ˜ë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” ê²½ìš°ëŠ” ë“œë¬¼ê¸° ë•Œë¬¸ì— ë‚´ë¶€ ë¡œì§ì€ ìœ ì§€
    user_interactions = {}
    user_interaction_counts = {}
    
    # ì „ì²´ ìƒí˜¸ì‘ìš© ë°ì´í„°ì—ì„œ ì‚¬ìš©ìë³„ë¡œ ê·¸ë£¹í™”
    for user_id in np.unique(dataset.pos_samples[:, 0]):
        user_id = int(user_id)
        # í˜„ì¬ ì‚¬ìš©ìì˜ ëª¨ë“  positive ìƒí˜¸ì‘ìš©
        user_items = dataset.pos_samples[dataset.pos_samples[:, 0] == user_id][:, 1]
        user_interaction_counts[user_id] = len(user_items)
        
        # ìµœì†Œ ìƒí˜¸ì‘ìš© ìˆ˜ í•„í„°ë§
        if len(user_items) >= min_interactions:
            # ì…”í”Œ
            np.random.shuffle(user_items)
            
            # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
            split_idx = max(1, int(len(user_items) * (1 - test_ratio)))
            train_items = user_items[:split_idx]
            test_items = user_items[split_idx:]
            
            if len(test_items) > 0:
                user_interactions[user_id] = {
                    'train': train_items,
                    'val': np.array([]),  # ì´ í•¨ìˆ˜ì—ì„œëŠ” ê²€ì¦ ì„¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
                    'test': test_items
                }
    
    # í‰ê°€í•  ì‚¬ìš©ì ì„ íƒ
    eval_users = list(user_interactions.keys())
    if num_users is not None and num_users < len(eval_users):
        eval_users = np.random.choice(eval_users, num_users, replace=False)
    
    # ìƒí˜¸ì‘ìš© í†µê³„ ê³„ì‚° ë° ì¶œë ¥ (ìœ ì§€)
    interactions_stats = [user_interaction_counts[u] for u in eval_users]
    avg_interactions = np.mean(interactions_stats)
    median_interactions = np.median(interactions_stats)
    min_inter = np.min(interactions_stats)
    max_inter = np.max(interactions_stats)
    
    print(f"í‰ê°€ ëŒ€ìƒ: {len(eval_users)}ëª…ì˜ ì‚¬ìš©ì")
    print(f"ì‚¬ìš©ì ìƒí˜¸ì‘ìš© í†µê³„:")
    print(f"  - í‰ê·  ìƒí˜¸ì‘ìš© ìˆ˜: {avg_interactions:.2f}")
    print(f"  - ì¤‘ì•™ê°’ ìƒí˜¸ì‘ìš© ìˆ˜: {median_interactions:.2f}")
    print(f"  - ìµœì†Œ ìƒí˜¸ì‘ìš© ìˆ˜: {min_inter}")
    print(f"  - ìµœëŒ€ ìƒí˜¸ì‘ìš© ìˆ˜: {max_inter}")
    
    # í†µí•© í‰ê°€ í•¨ìˆ˜ ì‚¬ìš©
    metrics = evaluate_recommendations(
        model, 
        eval_users, 
        user_interactions, 
        top_k=top_k, 
        interaction_type='test',
        mask_items_key='train',
        device=device
    )
    
    # ìƒí˜¸ì‘ìš© ìˆ˜ì— ë”°ë¥¸ ì„±ëŠ¥ ë¶„ì„
    # ì´ ë¶€ë¶„ì€ evaluate_model í•¨ìˆ˜ì—ë§Œ ìˆëŠ” ê³ ìœ í•œ ê¸°ëŠ¥ì´ë¯€ë¡œ ìœ ì§€
    interaction_bins = {
        '3-5': {'users': 0, 'MAP': [], 'Recall': [], 'NDCG': []},
        '6-10': {'users': 0, 'MAP': [], 'Recall': [], 'NDCG': []},
        '11+': {'users': 0, 'MAP': [], 'Recall': [], 'NDCG': []}
    }
    
    # ìƒí˜¸ì‘ìš© ìˆ˜ì— ë”°ë¥¸ ì„±ëŠ¥ ë°ì´í„° ìˆ˜ì§‘
    with torch.no_grad():
        for user_id in eval_users:
            # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ì•„ì´í…œ
            train_items = user_interactions[user_id]['train']
            test_items = user_interactions[user_id]['test']
            
            # í˜„ì¬ ì‚¬ìš©ìì— ëŒ€í•œ ëª¨ë“  ì•„ì´í…œ ì ìˆ˜ ì˜ˆì¸¡
            scores = model.predict(user_id)
            scores = scores.cpu().numpy()
            
            # í•™ìŠµ ì•„ì´í…œ ë§ˆìŠ¤í‚¹ (ì¶”ì²œì—ì„œ ì œì™¸)
            scores[train_items] = -np.inf
            
            # Top-K ì•„ì´í…œ ì¶”ì¶œ
            recommended_items = np.argsort(-scores)[:top_k]
            
            # í‰ê°€ ì§€í‘œ ê³„ì‚°
            precision, recall, ndcg = calculate_recommendation_metrics(
                recommended_items, test_items, top_k
            )
            
            # ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ìˆ˜ì— ë”°ë¥¸ ì„±ëŠ¥ ë°ì´í„° ìˆ˜ì§‘
            interaction_count = user_interaction_counts[user_id]
            if interaction_count <= 5:
                bin_key = '3-5'
            elif interaction_count <= 10:
                bin_key = '6-10'
            else:
                bin_key = '11+'
                
            interaction_bins[bin_key]['users'] += 1
            interaction_bins[bin_key]['MAP'].append(precision)
            interaction_bins[bin_key]['Recall'].append(recall)
            interaction_bins[bin_key]['NDCG'].append(ndcg)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\nì „ì²´ í‰ê°€ ê²°ê³¼:")
    for metric, value in metrics.items():
        print(f"  {metric}: {value:.4f}")
    
    # ìƒí˜¸ì‘ìš© ìˆ˜ì— ë”°ë¥¸ ì„±ëŠ¥ ì¶œë ¥
    print("\nìƒí˜¸ì‘ìš© ìˆ˜ì— ë”°ë¥¸ ì„±ëŠ¥ ë¶„ì„:")
    for bin_key, data in interaction_bins.items():
        if data['users'] > 0:
            print(f"  ìƒí˜¸ì‘ìš© {bin_key} ({data['users']}ëª…):")
            print(f"    - MAP@{top_k}: {np.mean(data['MAP']):.4f}")
            print(f"    - Recall@{top_k}: {np.mean(data['Recall']):.4f}")
            print(f"    - NDCG@{top_k}: {np.mean(data['NDCG']):.4f}")
    
    return metrics


# 4. ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜ ìˆ˜ì •
def train_bpr_model(
    triplet_file,
    output_dir="./models",
    embedding_dim=128,   
    learning_rate=0.005,
    weight_decay=0.00001, 
    batch_size=4096,
    epochs=50,
    validation_interval=1,
    device="cuda" if torch.cuda.is_available() else "cpu",
    verbose=True,
    save_model=True,
    dataloader_params=None
):
    """
    BPR ëª¨ë¸ í•™ìŠµ - ê²€ì¦ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ê³¼ì í•© ë°©ì§€ ê°œì„ 
    
    Args:
        triplet_file: íŠ¸ë¦¬í”Œë › JSON íŒŒì¼ ê²½ë¡œ
        output_dir: ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬
        embedding_dim: ì„ë² ë”© ì°¨ì›
        learning_rate: í•™ìŠµë¥ 
        weight_decay: ê°€ì¤‘ì¹˜ ê°ì†Œ (L2 ì •ê·œí™”)
        batch_size: ë°°ì¹˜ í¬ê¸°
        epochs: ì—í¬í¬ ìˆ˜
        validation_interval: ê²€ì¦ ê°„ê²© (ì—í¬í¬ ë‹¨ìœ„)
        device: í•™ìŠµ ì¥ì¹˜ ('cuda' ë˜ëŠ” 'cpu')
        verbose: ìì„¸í•œ ì¶œë ¥ ì—¬ë¶€
        save_model: ëª¨ë¸ ì €ì¥ ì—¬ë¶€
        dataloader_params: ë°ì´í„°ë¡œë” íŒŒë¼ë¯¸í„°
    """
    # í•™ìŠµ íŒŒë¼ë¯¸í„° ì¶œë ¥ í™•ì¸
    print(f"\nTraining parameters:")
    print(f"- Embedding dimension: {embedding_dim}")
    print(f"- Learning rate: {learning_rate}")
    print(f"- Weight decay (regularization): {weight_decay}")
    print(f"- Batch size: {batch_size}")
    print(f"- Epochs: {epochs}")
    print(f"- Validation interval: {validation_interval} epochs")
    
    # CUDA ë©”ëª¨ë¦¬ ìºì‹œ ë¹„ìš°ê¸°
    if device == 'cuda':
        torch.cuda.empty_cache()
    
    start_time = time.time()
    print(f"BPR model training started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"Device: {device}")
    
    # ê¸°ë³¸ ë°ì´í„°ë¡œë” íŒŒë¼ë¯¸í„° ì„¤ì •
    if dataloader_params is None:
        dataloader_params = {
            'batch_size': batch_size,
            'shuffle': True,
            'num_workers': 0 if device == 'cuda' else 4,
            'pin_memory': True if device == 'cuda' else False
        }
    
    # ë°ì´í„°ì…‹ ë¡œë“œ
    dataset = BPRDataset(triplet_file)
    
    # ë°ì´í„°ì…‹ ë¶„í•  (í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸)
    user_interactions = split_dataset(dataset, train_ratio=0.6, val_ratio=0.2, test_ratio=0.2, min_interactions=3)
    
    dataloader = DataLoader(
        dataset, 
        batch_size=dataloader_params.get('batch_size', batch_size),
        shuffle=dataloader_params.get('shuffle', True),
        num_workers=dataloader_params.get('num_workers', 0 if device == 'cuda' else 4),
        pin_memory=dataloader_params.get('pin_memory', True if device == 'cuda' else False)
    )
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    num_users = dataset.metadata.get('num_users', 0)
    num_items = dataset.metadata.get('num_businesses', 0)
    
    # ëª…ì‹œì ìœ¼ë¡œ embedding_dim ì „ë‹¬
    model = BPRModel(num_users, num_items, embedding_dim)
    model = model.to(device)
    
    # CUDA ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
    if device == 'cuda':
        print(f"Initial CUDA memory usage: {torch.cuda.memory_allocated() / 1024**2:.2f} MB")
    
    # ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € ì„¤ì •
    loss_function = BPRLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)
    
    # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì¶”ê°€ (10 ì—í¬í¬ë§ˆë‹¤ í•™ìŠµë¥  ê°ì†Œ)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)
    
    # í•™ìŠµ ê³¼ì • ì¶”ì 
    train_losses = []
    val_metrics_history = []
    
    # ì¡°ê¸° ì¢…ë£Œ ì„¤ì • (ê²€ì¦ ì†ì‹¤ ê¸°ì¤€)
    patience = 7
    min_delta = 0.0005
    best_val_ndcg = 0.0  # ê²€ì¦ NDCG ê¸°ì¤€ìœ¼ë¡œ ë³€ê²½
    wait = 0
    best_model = None
    best_epoch = 0
    
    # í•™ìŠµ ë£¨í”„
    for epoch in range(epochs):
        model.train()
        epoch_loss = 0
        epoch_start = time.time()
        
        for batch_idx, batch in enumerate(dataloader):
            # ë°°ì¹˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            user = batch['user'].to(device, non_blocking=True)
            pos_item = batch['pos_item'].to(device, non_blocking=True)
            neg_item = batch['neg_item'].to(device, non_blocking=True)
            
            # ê·¸ë˜ë””ì–¸íŠ¸ ì´ˆê¸°í™”
            optimizer.zero_grad(set_to_none=True)  # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ
            
            # ëª¨ë¸ í¬ì›Œë“œ íŒ¨ìŠ¤
            pos_scores, neg_scores = model(user, pos_item, neg_item)
            
            # ì†ì‹¤ ê³„ì‚°
            loss = loss_function(pos_scores, neg_scores)
            
            # ì—­ì „íŒŒ ë° ìµœì í™”
            loss.backward()
            optimizer.step()
            
            epoch_loss += loss.item()
            
            # GPU ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ (100 ë°°ì¹˜ë§ˆë‹¤)
            if device == 'cuda' and batch_idx % 100 == 0 and batch_idx > 0 and verbose:
                print(f"  Batch {batch_idx}/{len(dataloader)} - CUDA memory: {torch.cuda.memory_allocated() / 1024**2:.2f} MB")
        
        # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ë‹¨ê³„ ì§„í–‰
        scheduler.step()
        
        # ì—í¬í¬ í‰ê·  ì†ì‹¤
        epoch_loss /= len(dataloader)
        train_losses.append(epoch_loss)
        
        # ì—í¬í¬ ì •ë³´ ì¶œë ¥
        epoch_time = time.time() - epoch_start
        lr = scheduler.get_last_lr()[0]
        print(f"Epoch {epoch+1}/{epochs} - Training loss: {epoch_loss:.6f} - Time: {epoch_time:.2f}s - Learning rate: {lr:.6f}")
        
        # ê²€ì¦ ì„±ëŠ¥ ì¸¡ì • (ì§€ì •ëœ ê°„ê²©ë§ˆë‹¤)
        if (epoch + 1) % validation_interval == 0:
            val_metrics = validate_epoch(model, user_interactions, top_k=10, max_users=500, device=device)
            val_metrics_history.append(val_metrics)
            
            print(f"  Validation - MAP@10: {val_metrics['MAP']:.4f}, Recall@10: {val_metrics['Recall']:.4f}, NDCG@10: {val_metrics['NDCG']:.4f}")
            
            # ê²€ì¦ NDCG ê¸°ì¤€ìœ¼ë¡œ ìµœê³  ëª¨ë¸ ê°±ì‹ 
            if val_metrics['NDCG'] > best_val_ndcg + min_delta:
                best_val_ndcg = val_metrics['NDCG']
                wait = 0
                best_model = copy.deepcopy(model.state_dict())
                best_epoch = epoch + 1
                print(f"   ğŸ‘ New best validation NDCG: {best_val_ndcg:.4f} (Epoch {best_epoch})")
            else:
                wait += 1
                if wait >= patience:
                    print(f"Epoch {epoch+1}/{epochs}: Early stopping (no improvement for {patience} epochs)")
                    if best_model is not None:
                        model.load_state_dict(best_model)  # ìµœì  ëª¨ë¸ ë³µì›
                    break
    
    # í•™ìŠµ ì™„ë£Œ
    train_time = time.time() - start_time
    print(f"\nBPR model training completed - Total time: {train_time:.2f}s")
    
    if best_model is not None:
        model.load_state_dict(best_model)
        print(f"Restored best model (Epoch {best_epoch}, Validation NDCG: {best_val_ndcg:.4f})")
    
    # ì†ì‹¤ ë° ê²€ì¦ ì§€í‘œ ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
    plt.figure(figsize=(15, 6))
    
    # í•™ìŠµ ì†ì‹¤ ê·¸ë˜í”„
    plt.subplot(1, 2, 1)
    plt.plot(range(1, len(train_losses)+1), train_losses)
    plt.xlabel('Epoch')
    plt.ylabel('Training Loss')
    plt.title('BPR Model Training Loss')
    plt.grid(True)
    
    # ê²€ì¦ ì§€í‘œ ê·¸ë˜í”„
    if val_metrics_history:
        plt.subplot(1, 2, 2)
        epochs_with_val = [i * validation_interval for i in range(1, len(val_metrics_history)+1)]
        plt.plot(epochs_with_val, [m['MAP'] for m in val_metrics_history], 'b-', label='MAP@10')
        plt.plot(epochs_with_val, [m['Recall'] for m in val_metrics_history], 'r-', label='Recall@10')
        plt.plot(epochs_with_val, [m['NDCG'] for m in val_metrics_history], 'g-', label='NDCG@10')
        plt.xlabel('Epoch')
        plt.ylabel('Validation Metrics')
        plt.title('BPR Model Validation Performance')
        plt.legend()
        plt.grid(True)
    
    # ì†ì‹¤ ê·¸ë˜í”„ ì €ì¥
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    plt.savefig(os.path.join(output_dir, "bpr_training_metrics.png"))
    
    # ëª¨ë¸ ì €ì¥ (ë²„ì „ ê´€ë¦¬)
    if save_model:
        # ë‹¤ìŒ ëª¨ë¸ ë²„ì „ ë²ˆí˜¸ ê°€ì ¸ì˜¤ê¸°
        model_version = get_next_model_version(output_dir)
        model_filename = f"bpr_model_{model_version}.pt"
        model_path = os.path.join(output_dir, model_filename)
        
        # ìµœì‹  ëª¨ë¸ ì •ë³´ í¬í•¨í•˜ì—¬ ì €ì¥
        model_info = {
            'model_state': model.state_dict(),
            'metadata': dataset.metadata,
            'embedding_dim': embedding_dim,
            'user_id_map': dataset.user_id_map,
            'business_id_map': dataset.business_id_map,
            'timestamp': datetime.now().isoformat(),
            'version': model_version,
            'learning_rate': learning_rate,
            'weight_decay': weight_decay,
            'batch_size': batch_size,
            'epochs_trained': len(train_losses),
            'final_loss': train_losses[-1],
            'best_epoch': best_epoch,
            'best_val_ndcg': best_val_ndcg,
            'validation_metrics_history': val_metrics_history
        }
        torch.save(model_info, model_path)
        print(f"Model saved (Version {model_version}): {model_path}")
        
        # ìµœì‹  ëª¨ë¸ ì‹¬ë³¼ë¦­ ë§í¬ ìƒì„± (í•­ìƒ ìµœì‹  ëª¨ë¸ì„ ê°€ë¦¬í‚¤ë„ë¡)
        latest_model_path = os.path.join(output_dir, "bpr_model_latest.pt")
        torch.save(model_info, latest_model_path)
        print(f"Latest model link updated: {latest_model_path}")
    
    return model, dataset, model_version if save_model else None, user_interactions


# 5. ëª¨ë¸ í‰ê°€ ì§€í‘œ ë° ì¶”ì²œ ìƒì„±
def evaluate_and_recommend(
    model,
    dataset,
    top_k=10,
    num_users=None,
    device="cuda" if torch.cuda.is_available() else "cpu"
):
    """
    ëª¨ë¸ í‰ê°€ ë° ì¶”ì²œ ìƒì„±
    
    Args:
        model: í•™ìŠµëœ BPR ëª¨ë¸
        dataset: BPR ë°ì´í„°ì…‹
        top_k: ì¶”ì²œí•  ì•„ì´í…œ ìˆ˜
        num_users: í‰ê°€í•  ì‚¬ìš©ì ìˆ˜ (Noneì´ë©´ ëª¨ë“  ì‚¬ìš©ì)
    """
    model.eval()
    model = model.to(device)
    
    # í‰ê°€í•  ì‚¬ìš©ì ì„ íƒ
    unique_users = np.unique(dataset.data[:, 0])
    if num_users is not None and num_users < len(unique_users):
        sample_users = np.random.choice(unique_users, num_users, replace=False)
    else:
        sample_users = unique_users
    
    print(f"\n{len(sample_users)}ëª…ì˜ ì‚¬ìš©ìì— ëŒ€í•œ ì¶”ì²œ ìƒì„± ì¤‘...")
    
    # ì¶”ì²œ ê²°ê³¼ ì €ì¥
    recommendations = {}
    
    with torch.no_grad():
        for user_idx in sample_users:
            # ì‚¬ìš©ìì˜ ê¸ì •ì  ì•„ì´í…œ (ì´ë¯¸ ìƒí˜¸ì‘ìš©í•œ ì•„ì´í…œ)
            user_positives = dataset.pos_samples[dataset.pos_samples[:, 0] == user_idx][:, 1]
            
            # ì‚¬ìš©ìì— ëŒ€í•œ ëª¨ë“  ì•„ì´í…œ ì ìˆ˜ ì˜ˆì¸¡
            user_tensor = torch.tensor([user_idx], dtype=torch.long, device=device)
            scores = model.predict(user_idx)
            
            # ì´ë¯¸ ìƒí˜¸ì‘ìš©í•œ ì•„ì´í…œ ë§ˆìŠ¤í‚¹ (ì¶”ì²œì—ì„œ ì œì™¸)
            scores = scores.cpu().numpy()
            scores[user_positives] = -np.inf
            
            # Top-K ì•„ì´í…œ ì¶”ì¶œ
            top_items = np.argsort(-scores)[:top_k]
            
            # ì•„ì´í…œ IDì™€ ì ìˆ˜ ì €ì¥
            recommendations[int(user_idx)] = [
                (int(item_idx), float(scores[item_idx])) for item_idx in top_items
            ]
    
    # ê²°ê³¼ ì˜ˆì‹œ ì¶œë ¥
    print("\nì¶”ì²œ ì˜ˆì‹œ:")
    for i, (user_idx, items) in enumerate(list(recommendations.items())[:3]):
        original_user_id = None
        if dataset.user_id_map and 'idx_to_id' in dataset.user_id_map:
            original_user_id = dataset.user_id_map['idx_to_id'].get(str(user_idx), user_idx)
        
        print(f"ì‚¬ìš©ì {user_idx} (ì›ë³¸ ID: {original_user_id}):")
        for j, (item_idx, score) in enumerate(items[:5]):
            original_item_id = None
            if dataset.business_id_map and 'idx_to_id' in dataset.business_id_map:
                original_item_id = dataset.business_id_map['idx_to_id'].get(str(item_idx), item_idx)
            
            print(f"  {j+1}. ì•„ì´í…œ {item_idx} (ì›ë³¸ ID: {original_item_id}) - ì ìˆ˜: {score:.4f}")
    
    return recommendations


# íŒŒì¼ì— ìˆëŠ” evaluate_and_recommend í•¨ìˆ˜ ë‹¤ìŒì— ì•„ë˜ ì½”ë“œ ì¶”ê°€
def load_bpr_model(model_path_or_dir, version=None, device="cuda" if torch.cuda.is_available() else "cpu"):
    """
    ì €ì¥ëœ BPR ëª¨ë¸ ë¡œë“œ
    
    Args:
        model_path_or_dir: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ë˜ëŠ” ëª¨ë¸ ë””ë ‰í† ë¦¬
        version: ë¡œë“œí•  ëª¨ë¸ ë²„ì „ (Noneì´ë©´ ìµœì‹  ë²„ì „ ë˜ëŠ” ì§€ì •ëœ ê²½ë¡œ ì‚¬ìš©)
        device: ë¡œë“œí•  ì¥ì¹˜
    
    Returns:
        model: ë¡œë“œëœ BPR ëª¨ë¸
        model_info: ëª¨ë¸ ë©”íƒ€ë°ì´í„°
    """
    if os.path.isdir(model_path_or_dir):
        # ë””ë ‰í† ë¦¬ê°€ ì œê³µëœ ê²½ìš°
        if version is None:
            # ìµœì‹  ë²„ì „ ì°¾ê¸°
            model_path = os.path.join(model_path_or_dir, "bpr_model_latest.pt")
            if not os.path.exists(model_path):
                # latest ë§í¬ê°€ ì—†ëŠ” ê²½ìš° ê°€ì¥ ë†’ì€ ë²„ì „ ì°¾ê¸°
                next_version = get_next_model_version(model_path_or_dir) - 1
                if next_version < 1:
                    raise FileNotFoundError(f"ëª¨ë¸ ë””ë ‰í† ë¦¬ì— ëª¨ë¸ íŒŒì¼ì´ ì—†ìŒ: {model_path_or_dir}")
                model_path = os.path.join(model_path_or_dir, f"bpr_model_{next_version}.pt")
        else:
            # íŠ¹ì • ë²„ì „ ë¡œë“œ
            model_path = os.path.join(model_path_or_dir, f"bpr_model_{version}.pt")
    else:
        # íŒŒì¼ ê²½ë¡œê°€ ì§ì ‘ ì œê³µëœ ê²½ìš°
        model_path = model_path_or_dir
    
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {model_path}")
    
    # ëª¨ë¸ ì •ë³´ ë¡œë“œ
    model_info = torch.load(model_path, map_location=device)
    
    # ëª¨ë¸ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
    num_users = model_info['metadata'].get('num_users', 0)
    num_items = model_info['metadata'].get('num_businesses', 0)
    embedding_dim = model_info.get('embedding_dim', 128)
    
    # ëª¨ë¸ ì´ˆê¸°í™” ë° ê°€ì¤‘ì¹˜ ë¡œë“œ
    model = BPRModel(num_users, num_items, embedding_dim)
    model.load_state_dict(model_info['model_state'])
    model = model.to(device)
    model.eval()  # í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
    
    # ëª¨ë¸ ë²„ì „ ì •ë³´
    version_info = f"(ë²„ì „ {model_info.get('version', 'ì•Œ ìˆ˜ ì—†ìŒ')})" if 'version' in model_info else ""
    
    print(f"BPR ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path} {version_info}")
    print(f"- ì‚¬ìš©ì ìˆ˜: {num_users}")
    print(f"- ë¹„ì¦ˆë‹ˆìŠ¤ ìˆ˜: {num_items}")
    print(f"- ì„ë² ë”© ì°¨ì›: {embedding_dim}")
    
    # ì¶”ê°€ ëª¨ë¸ ì •ë³´ í‘œì‹œ
    if 'learning_rate' in model_info:
        print(f"- í•™ìŠµë¥ : {model_info['learning_rate']}")
    if 'epochs_trained' in model_info:
        print(f"- í•™ìŠµ ì—í¬í¬: {model_info['epochs_trained']}")
    if 'final_loss' in model_info:
        print(f"- ìµœì¢… ì†ì‹¤: {model_info['final_loss']:.6f}")
    if 'timestamp' in model_info:
        print(f"- ì €ì¥ ì‹œê°„: {model_info['timestamp']}")
    
    return model, model_info


# 6. ë©”ì¸ í•¨ìˆ˜
if __name__ == "__main__":
    # íŒŒì¼ ê²½ë¡œ ì„¤ì •
    triplet_file = "philly_bpr_triplets.json"
    output_dir = "./bpr_model"
    
    # í˜„ì¬ ì‹¤í–‰ í™˜ê²½ ì •ë³´ ì¶œë ¥
    print("\n" + "="*50)
    print("Environment Information")
    print("="*50)
    print(f"PyTorch version: {torch.__version__}")
    print(f"CUDA available: {torch.cuda.is_available()}")
    
    # CUDA ë²„ì „ ì •ë³´ ì¶œë ¥
    if torch.cuda.is_available():
        print(f"CUDA version: {torch.version.cuda}")
        print(f"CUDNN version: {torch.backends.cudnn.version()}")
        print(f"CUDA device count: {torch.cuda.device_count()}")
        print(f"Current CUDA device: {torch.cuda.current_device()}")
        print(f"CUDA device name: {torch.cuda.get_device_name(0)}")
        
        # CUDNN ìë™ íŠœë„ˆ ì„¤ì •
        torch.backends.cudnn.benchmark = True
        print("CUDNN benchmark enabled: Using CUDNN auto-tuner for performance optimization")
    
    # GPU ì„¤ì • ë° ìµœì í™”
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    if device == 'cuda':
        print(f"Using GPU {torch.cuda.get_device_name(0)}")
        batch_size = 4096
        num_workers = 0
        pin_memory = True
    else:
        print("Using CPU")
        batch_size = 1024
        num_workers = 4
        pin_memory = False
    
    # í•™ìŠµ ì„¤ì •
    embedding_dim = 128   # 128ë¡œ ë³µì›
    learning_rate = 0.005
    weight_decay = 0.00001  # 0.00001ë¡œ ë³µì›
    epochs = 50
    
    print(f"\nTraining settings:")
    print(f"  Device: {device}")
    print(f"  Batch size: {batch_size}")
    print(f"  Embedding dimension: {embedding_dim}")
    print(f"  Learning rate: {learning_rate}")
    print(f"  Weight decay (regularization): {weight_decay}")
    print(f"  Epochs: {epochs}")
    
    # GPU í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸
    if device == 'cuda':
        try:
            print("\nGPU compatibility test...")
            test_tensor = torch.FloatTensor([1.0, 2.0, 3.0]).to(device)
            test_result = test_tensor * 2
            print(f"Test result: {test_result.cpu().numpy()}")
            
            # ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸
            print("GPU memory test...")
            x = torch.rand(1000, 1000).to(device)
            y = torch.matmul(x, x.t())
            allocated = torch.cuda.memory_allocated() / 1024**2
            print(f"Allocated memory: {allocated:.2f} MB")
            del x, y
            torch.cuda.empty_cache()
            
            print("GPU compatibility test successful!")
        except Exception as e:
            print(f"GPU compatibility test failed: {str(e)}")
            print("Switching to CPU.")
            device = "cpu"
            batch_size = 1024
            num_workers = 4
            pin_memory = False
    
    # ë°ì´í„°ë¡œë” ì„¤ì • íŒŒë¼ë¯¸í„°
    dataloader_params = {
        'batch_size': batch_size,
        'shuffle': True,
        'num_workers': num_workers,
        'pin_memory': pin_memory,
        'drop_last': True  # ë§ˆì§€ë§‰ ë¶ˆì™„ì „í•œ ë°°ì¹˜ ë¬´ì‹œ (ì„±ëŠ¥ í–¥ìƒ)
    }
    
    # ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ ì—¬ë¶€ í™•ì¸
    latest_model_path = os.path.join(output_dir, "bpr_model_latest.pt")
    train_model = True  # ê¸°ë³¸ê°’: í•™ìŠµ ì§„í–‰
    model_version = None
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë²„ì „ í‘œì‹œ
    available_versions = []
    if os.path.exists(output_dir):
        model_files = [f for f in os.listdir(output_dir) if f.startswith('bpr_model_') and f.endswith('.pt')]
        for file in model_files:
            try:
                if file != "bpr_model_latest.pt":
                    version_str = file.replace('bpr_model_', '').replace('.pt', '')
                    version = int(version_str)
                    available_versions.append(version)
            except ValueError:
                continue
    
    if available_versions:
        available_versions.sort(reverse=True)
        print(f"\nAvailable model versions: {available_versions}")
    
    if os.path.exists(latest_model_path):
        print(f"\nExisting model found: {latest_model_path}")
        use_model = input("Use existing model? (y/n): ")
        
        if use_model.lower() == 'y':
            train_model = False
            
            # ê¸°ì¡´ ëª¨ë¸ ë²„ì „ ì„ íƒ ì—¬ë¶€
            if len(available_versions) > 1:
                select_version = input(f"Use specific version? Available versions: {available_versions} (y/n): ")
                if select_version.lower() == 'y':
                    while True:
                        try:
                            version_input = input("Enter version number: ")
                            model_version = int(version_input)
                            if model_version in available_versions:
                                break
                            else:
                                print(f"Invalid version number. Available versions: {available_versions}")
                        except ValueError:
                            print("Please enter a number.")
            
            # ëª¨ë¸ ë¡œë“œ
            model, model_info = load_bpr_model(output_dir, version=model_version, device=device)
            
            # ë°ì´í„°ì…‹ ë¡œë“œ (í‰ê°€ ìœ„í•´)
            dataset = BPRDataset(triplet_file)
            
            # ë°ì´í„°ì…‹ ë¶„í•  (ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš© ì‹œì—ë„ í‰ê°€ë¥¼ ìœ„í•´)
            user_interactions = split_dataset(dataset, train_ratio=0.6, val_ratio=0.2, test_ratio=0.2, min_interactions=3)
        else:
            print("Training new model.")
    
    # ëª¨ë¸ í•™ìŠµ
    if train_model:
        model, dataset, model_version, user_interactions = train_bpr_model(
            triplet_file, 
            output_dir, 
            embedding_dim,
            learning_rate,
            weight_decay,
            batch_size,
            epochs,
            validation_interval=1,  # ë§¤ ì—í¬í¬ë§ˆë‹¤ ê²€ì¦
            device=device,
            verbose=True,
            save_model=True,
            dataloader_params=dataloader_params
        )
    
    # ì„±ëŠ¥ í‰ê°€ (í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì‚¬ìš©)
    print("\nFinal performance evaluation on test set...")
    
    # í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ í‰ê°€
    metrics_k10 = evaluate_test_set(model, user_interactions, top_k=10, device=device)
    
    # ì¶”ì²œ ìƒì„± ì˜ˆì‹œ
    recommendations = evaluate_and_recommend(
        model, 
        dataset, 
        top_k=10, 
        num_users=5,
        device=device
    )
    
    print("\nTraining and recommendation generation completed!")
    
    # ëª¨ë¸ ì •ë³´
    print("\nModel information:")
    print(f"- Model version: {model_version}")
    print(f"- Embedding dimension: {embedding_dim}")
    print(f"- Training device: {device}")
    print(f"- Batch size: {batch_size}")
    print(f"- Regularization: {weight_decay}")
    
    # í•™ìŠµ ì‹œê°„ ë¹„êµ ì •ë³´ ì¶”ê°€
    if 'train_losses' in train_bpr_model.__globals__ and train_model:
        final_loss = train_bpr_model.__globals__['train_losses'][-1]
        print(f"- Final loss: {final_loss:.6f}")
    
    # í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ ì§€í‘œ ìš”ì•½
    print("\nTest performance metrics:")
    for metric, value in metrics_k10.items():
        print(f"- {metric}: {value:.4f}")
    
    print("\nTraining logs and graphs: bpr_training_metrics.png") 
